---
title: "Model Building and Statistical Analysis for Palmer Penguins Dataset (Task 2)"
author: "Christian Rodriguez"
date: "2024-11-27"
output: 
  word_document:
    toc: true
    toc_depth: 3
---

# Introduction

In this analysis, I build and evaluate predictive models to understand the factors influencing penguin body mass. I assess model assumptions, perform transformations when necessary, and compare multiple models using Adjusted R², AIC, and BIC criteria to select the best-fitting model.

# Load Necessary Libraries

```{r setup, include=TRUE}
# Load required libraries
library(palmerpenguins)  # For the penguins dataset
library(dplyr)           # For data manipulation
library(ggplot2)         # For data visualization
library(tidyr)           # For data tidying
library(broom)           # For tidying model outputs
```

# Load and Preprocess the Dataset

```{r load-data}
# Load the penguins dataset
data("penguins")
df <- penguins

# Impute missing numerical values with median by species
numerical_vars <- c("bill_length_mm", "bill_depth_mm", "flipper_length_mm", "body_mass_g")
df <- df %>%
  group_by(species) %>%
  mutate(across(all_of(numerical_vars), ~ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
  ungroup()

# Function to calculate mode
get_mode <- function(v) {
  uniqv <- unique(v[!is.na(v)])
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Impute missing categorical values with mode by species
df <- df %>%
  group_by(species) %>%
  mutate(sex = ifelse(is.na(sex), get_mode(sex), sex)) %>%
  ungroup()

# Verify no missing values remain
colSums(is.na(df))
```

# Create Derived Variables

```{r create-bmi}
# Create a BMI-like variable
df <- df %>%
  mutate(
    weight_kg = body_mass_g / 1000,
    flipper_length_m = flipper_length_mm / 1000,
    BMI = weight_kg / (flipper_length_m^2)
  )
```

# Prepare Data for Modeling

```{r prepare-model-data}
# Select relevant variables for modeling
model_data <- df %>%
  select(body_mass_g, bill_length_mm, bill_depth_mm, flipper_length_mm, species, sex, island, BMI) %>%
  na.omit()

# Encode categorical variables as factors
model_data$species <- as.factor(model_data$species)
model_data$sex <- as.factor(model_data$sex)
model_data$island <- as.factor(model_data$island)
```

# Exploratory Data Analysis for Modeling

```{r eda-modeling}
# Pairwise correlations
pairs(model_data %>% select(bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, BMI),
      main = "Pairwise Scatter Plots")
```

# Model Building

## Model 1: Full Model with All Predictors

```{r model1}
# Build linear regression model using all predictors
model1 <- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex + island + BMI, data = model_data)
summary(model1)
```

# Check Model Assumptions

```{r plot-model1, fig.height=8, fig.width=10, warning=FALSE, message=FALSE}
# Plot diagnostic plots for Model 1
par(mfrow = c(2, 2))
plot(model1)
par(mfrow = c(1, 1))  # Reset to default
```

### Interpretation:

-   **Residuals vs Fitted**:\
    The residuals appear to show a curved pattern, indicating potential non-linearity in the relationship between the predictors and the response variable. There is also some evidence of heteroscedasticity (non-constant variance), as the spread of residuals changes across fitted values.

<!-- -->

-   **Normal Q-Q Plot**:\
    The residuals mostly follow the reference line, suggesting that the assumption of normality is reasonable. However, some deviations at the tails indicate potential outliers or non-normality in the residuals.

-   **Scale-Location**:\
    The plot shows a curved pattern, with variability in the spread of residuals across fitted values. This suggests heteroscedasticity, as the variance is not constant across the range of fitted values.

-   **Residuals vs Leverage**:\
    The plot identifies a few points with high leverage (e.g., points outside the dashed Cook’s distance lines). These points may have a disproportionate influence on the model and should be examined further to determine if they are problematic.

## Model 2: Log-Transformed Response Variable

### Rationale

If Model 1 violates assumptions such as normality of residuals or heteroscedasticity, a log transformation of the response variable can help stabilize variance and improve normality.

```{r model2}
# Add log-transformed response variable
model_data <- model_data %>%
  mutate(log_body_mass_g = log(body_mass_g))

# Build linear regression model with log-transformed response
model2 <- lm(log_body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex + island + BMI, data = model_data)
summary(model2)
```

# Check Model Assumptions for Model 2

```{r plot-model2, fig.height=8, fig.width=10, warning=FALSE, message=FALSE}
# Plot diagnostic plots for Model 2
par(mfrow = c(2, 2))
plot(model2)
par(mfrow = c(1, 1))  # Reset to default
```

### Interpretation:

-   **Residuals vs Fitted**:\
    The residuals show a curved pattern, indicating potential non-linearity even after the log transformation. This suggests the model may still not fully capture the relationship between predictors and the response variable.

-   **Normal Q-Q Plot**:\
    The residuals deviate from the reference line at both ends, indicating potential non-normality in the residuals, especially in the tails. This suggests that the log transformation did not fully address the normality issue.

-   **Scale-Location**:\
    The variability in the spread of residuals is not constant, as indicated by the slightly curved pattern. This suggests that heteroscedasticity persists even after the log transformation.

-   **Residuals vs Leverage**:\
    A few points are influential, with one or more points close to or outside the Cook's distance line. These observations should be further investigated as they may disproportionately affect the model.

### Summary

The log transformation has improved the model to some extent, but residual diagnostics suggest that further adjustments, such as exploring interactions, polynomial terms, or alternative transformations, may be necessary to improve the model's fit.

# Model Comparison

## Using Adjusted R², AIC, and BIC

```{r model-comparison}
# Compare Model 1 and Model 2 using AIC and BIC
AIC(model1, model2)
BIC(model1, model2)

# Extract Adjusted R² for both models
adj_r2_model1 <- summary(model1)$adj.r.squared
adj_r2_model2 <- summary(model2)$adj.r.squared

# Print Adjusted R² values
adj_r2_model1
adj_r2_model2
```

### Interpretation:

-   **Adjusted R²:**\
    Higher Adjusted R² values indicate a better model fit while accounting for the number of predictors. In this case, Model 2 has a significantly higher Adjusted R² compared to Model 1, suggesting it explains more variance in the response variable while accounting for model complexity.

<!-- -->

-   **AIC and BIC:**\
    Lower AIC and BIC values indicate a better trade-off between model fit and complexity. Model 2 has much lower AIC and BIC values than Model 1, indicating that it achieves a significantly better balance between goodness of fit and model simplicity.

## Model 3: Reduced Model with Significant Predictors

### Rationale

To simplify the model and potentially improve performance, I exclude less significant predictors based on Model 1's summary.

```{r model3}
# Build a reduced model excluding non-significant predictors (e.g., BMI)
model3 <- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species + sex + island, data = model_data)
summary(model3)
```

# Compare All Models

```{r compare-all-models}
# Compare AIC and BIC for all three models
aic_values <- AIC(model1, model2, model3)
bic_values <- BIC(model1, model2, model3)

# Display AIC and BIC values for comparison
print("AIC Values for All Models:")
aic_values

print("BIC Values for All Models:")
bic_values

# Extract Adjusted R² for all models
adj_r2_model1 <- summary(model1)$adj.r.squared
adj_r2_model2 <- summary(model2)$adj.r.squared
adj_r2_model3 <- summary(model3)$adj.r.squared

# Display Adjusted R² values for comparison
print("Adjusted R² for All Models:")
c(Model1 = adj_r2_model1, Model2 = adj_r2_model2, Model3 = adj_r2_model3)
```

### Interpretation:

-   **Lowest AIC and BIC:**\
    The model with the **lowest AIC and BIC values** is considered the best, as it strikes the optimal balance between model fit and complexity. In this case:

    -   **Model 2** has the lowest AIC (-2346.969) and BIC (-2304.722), making it the best model among the three in terms of balancing fit and complexity.

    -   **Model 1** has moderate AIC (3730.348) and BIC (3772.596) values, suggesting a poorer fit compared to Model 2.

    -   **Model 3** has the highest AIC (4915.891) and BIC (4950.457), indicating it is the least favorable model.

-   **Adjusted R²:**\
    Adjusted R² helps assess how well the model explains the variance in the response variable while accounting for the number of predictors:

    -   **Model 2** has the highest Adjusted R² (0.9982541), indicating it explains the most variance after considering model complexity.

    -   **Model 1** has a slightly lower Adjusted R² (0.9954861), indicating a good fit but less optimal than Model 2.

    -   **Model 3** has a much lower Adjusted R² (0.8575254), suggesting that it explains significantly less variance than Models 1 and 2.

### Final Summary:

Model 2 is the best model among the three, as it has the **lowest AIC and BIC values** and the **highest Adjusted R²**, making it the most balanced and explanatory model. While Model 1 is also a strong contender, Model 2 provides a substantially better fit, and Model 3 performs the worst based on all criteria.

# Model Selection

Based on the comparison criteria, select the model with the best balance between fit and simplicity.

```{r select-model}
# Select Model 2 as it has the lowest AIC and BIC and highest Adjusted R²
selected_model <- model2
summary(selected_model)
```

# Final Model Diagnostics

```{r final-model-diagnostics, fig.height=8, fig.width=10, warning=FALSE, message=FALSE}
# Plot diagnostic plots for the selected model
par(mfrow = c(2, 2))  # Set plotting layout for diagnostics
plot(selected_model)  # Generate diagnostic plots
par(mfrow = c(1, 1))  # Reset to default plotting layout
```

# Conclusion

Through systematic model building and evaluation, I identified **Model 2** as the most suitable linear regression model for predicting penguin body mass. This model demonstrates the best balance between complexity and performance, adheres to regression assumptions, and identifies significant predictors of penguin body mass. Its metrics, including the lowest AIC and BIC values and the highest Adjusted R², confirm its superiority over other models.
